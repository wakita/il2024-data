{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# このデータはなに？\n\n情報科目実施委員会 (2024-04-01)\n\n## どんな研究から生まれたデータなの？\n\nこの実習のために配布したデータは，元々は理学部情報科学科に在籍していた鶴見敏行さんが国際学会での発表のために準備したものを用いて，この実習のために一部を取り出したものです．鶴見さんの英文論文を和訳したものは，この授業の論文執筆の実習でも利用します．\n\nまず，簡単に「大規模社会ネットワークからのクラスタ構造の抽出」と題する鶴見さんの研究の内容について紹介します．ここで社会ネットワークとは，人間関係を意味します．いまでは mixi といえば，モンスターストライクというスマートフォン向けのゲームを思い浮べるかと思います．でも，１０年前の mixi は日本最大のソーシャルネットワーキングシステム(SNS)を運営していました．当時は誰しもが mixi をしていた時代で，計算機演習室でも授業を聞かないでオレンジ色の mixi カラーの画面を開いている人がぽつぽついた時代です。学生にとって mixi は今日の YouTube や TokTok のような地位を占めていました。\n\n鶴見さんが研究したのは mixi がサービスを急拡大していた時期でした。 mixi のサービスを利用している人々の友人関係を分析することで，人々に共通する関心事を見つけられるのではないかという点に興味を持っていました．また，そのような特性を見極めて，当時のやや不安定だった mixi のサービスの効率を改善することも隠れた目標でした．\n\n彼の研究に先だつ数年前に，社会ネットワークのなかから濃密な人間関係を高速に見つけられる手法の研究が始まっていました．当時，もっとも注目されていたのがClausetらが提案し，鶴見さんの論文のなかでCNM手法と読んでいる方法です．それまでの提案では，数千人程度の小さな規模の社会ネットワークしか分析できなかったのですが，CNM手法を利用することで十万人規模のネットワークの分析ができ，Clausetの論文には数百万人規模のネットワークへの応用も示唆されていました．\n\nそこで鶴見さんがCNM法のプログラムを作成し，mixi から取得した９０万人程度の友人関係のネットワークの分析を始めました．最初の予想では数日で結果が出るかと思っていたのですが，一週間たっても分析は全体の１０％も進みませんでした．鶴見さんはほかの勉強もしながら，そのプログラムを動かせっぱなしにしていたのですが，一月たった様子から分析には半年以上がかかることが明らかになりました．巨大な社会ネットワークに CNM 法を適用するのは最初は効率がよいです。でも、だんだんと非効率になりました．この様子を可視化したグラフが図２：ネットワークの解析に要した時間の時系列遷移です．\n\n当初の予定では，分析はあっという間に終ることを期待し，分析結果からなにかを発見するつもりでした．でも，思いがけないことに分析がなかなか終らないため，予定を変更し，分析手法自体を研究することにしました．\n\nまず、Clauset らが数百万まで応用できると主張しているにも関わらず，分析がなかなか終らない原因について調べました．明らかになったのは，鶴見さんの論文のなかで提案している合併比率と呼ばれる指標にかかわる問題でした．詳しい内容は鶴見さんの論文を読んでいただくことにしますが，合併比率が悪化した様子を表した結果が今回配布する図３：CNM法におけるクラスターの合併比率の推移（片対数）です．\n\n効率悪化の原因が明らかになったので，その問題を解決する方針を立て，それを実施したのが鶴見さんの研究成果です．彼は HE 法，HE’ 法，HN 法と呼ぶ３つの高速化手法を提案しました．Clauset らが提案した既存の提案を少し改良することで，mixi から得た５５０万人規模の 友人関係まで分析することができました．この結果は，「図６：スケーラビリティの HN 手法」として示されています．このグラフは縦軸が処理時間です．HN 法はあまりに短時間で終了するため，グラフでは横軸とほぼ重なっています．\n\n## データセットの内容はどうなっているの？\n\n鶴見さんの論文では，CNM 法とそれを改善した HE 法，HE’ 法，HN 法についてのいくつかの比較実験をしています．\n\n| 手法 | データ数 | データの大きさ |\n| :--- | ---: | ---: |\n| CNM | 16 | 36.1 MB |\n| HE  | 20 | 14.2 MB |\n| HE’ | 13 | 14.4 MB |\n| HN  | 17 | 13.6 MB |\n| 合計 | 66\t| 78.3 MB |\n\n実際にはこれだけのデータを作成したのですが，論文のなかで用いたデータはその一部です． でも，論文に使わなかったデータが無駄になったわけではありません．紙面の都合上，論文には掲載しなかったデータが多かったのですが，発表資料スライドには論文には掲載しなかった図表も提示しためので，結局，無駄になったデータはほとんどなかったと思います．\n\nみなさんに学んで欲しいのは，研究発表をするときには事前にかなりの分量のデータを用意するという点です．鶴見さんの研究で用いたデータの総量は 66個のデータセットで、総量は 78.3 MBでした．\n\nこのように数量ともに多くのファイルをどのように管理すればよいのかという点は，この実習の隠れたテーマのひとつです．\n\n\n## 内容物一覧\n\n- [`README.md`](README.md): このファイル\n\n- [data](data) いくつかの手法を実行して得られたデータを、手法ごとに整理したフォルダ (`cnm`, `he1`, `he2`, `hn`) に整理して保存してあります。それぞれのフォルダに設置されたデータの内容については、各フォルダの README.md をご覧下さい。\n\n- [images](images) 画像の出力先のフォルダ。Jupyter Lite 環境では画像を出力するための `write_image(...)` 機能を利用することができません。\n\n- `ex*.ipynb`: 実習のノートブック群\n\n- [`requirements.txt`](requirements.txt): 実習環境を素の Python から構築するときに必要となるファイル。",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}